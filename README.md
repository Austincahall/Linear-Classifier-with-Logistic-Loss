# Linear-Classifier-with-Logistic-Loss
Linear Classifier with Logistic Loss. Also experimenting with batch size and learning rates

This program uses Pytorch and requires no extra files. It uses the MNIST dataset. The only thing is that it turns it into a 2 class problem keping only 6 and 0. 

It uses logistic loss. 

First graph is error rates with different learning rates but same epochs

Second graph is error rate and batch size. [larger batches leads to larger error rate because total epochs stay the same]

Third Graph is error rate with training set size. obviously the less data in the training set, the less accurate the model was.

Jupyter Notebook included to prevent running of code.